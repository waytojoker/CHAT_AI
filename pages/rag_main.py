import streamlit as st
import ollama
from modules.rag_module import show_rag_management, RAGSystem
from modules.enhanced_conversation_display import (
    display_rag_enhanced_conversation,
    show_rag_settings,
    show_rag_debug_info
)
from modules.file_processing import get_file_content
from modules.history_module import show_conversation_history
from modules.model_service import create_model_service, ModelService, QianfanModelService, OllamaModelService
import os

# é¡µé¢é…ç½®
#éšè—è‡ªåŠ¨å¯¼èˆª2
st.markdown("""
<style>
    [data-testid="stSidebarNav"] {
        display: none !important;
    }
</style>
""", unsafe_allow_html=True)



# åˆå§‹åŒ–session state
def init_session_state():
    """åˆå§‹åŒ–session stateå˜é‡"""
    if "message" not in st.session_state:
        st.session_state["message"] = []

    if "current_conversation" not in st.session_state:
        st.session_state["current_conversation"] = 1

    if "show_history" not in st.session_state:
        st.session_state["show_history"] = False

    if "temperature" not in st.session_state:
        st.session_state["temperature"] = 0.7

    if "role_config" not in st.session_state:
        st.session_state["role_config"] = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹"

    if "scene_config" not in st.session_state:
        st.session_state["scene_config"] = "æ—¥å¸¸å¯¹è¯åœºæ™¯"

    if "task_config" not in st.session_state:
        st.session_state["task_config"] = "å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæä¾›æœ‰ç”¨çš„ä¿¡æ¯"

    if "use_rag" not in st.session_state:
        st.session_state["use_rag"] = False

    if "rag_system" not in st.session_state:
        st.session_state["rag_system"] = RAGSystem()

    if "show_rag_debug" not in st.session_state:
        st.session_state["show_rag_debug"] = False

    if "chunk_size" not in st.session_state:
        st.session_state["chunk_size"] = 500

    if "top_k" not in st.session_state:
        st.session_state["top_k"] = 3

    if "selected_model" not in st.session_state:
        st.session_state["selected_model"] = ""

    if "use_stream" not in st.session_state:
        st.session_state["use_stream"] = True

    if "maxHistoryMessages" not in st.session_state:
        st.session_state["maxHistoryMessages"] = 10

    if "model_service_type" not in st.session_state:
        st.session_state["model_service_type"] = "ollama"

    if "model_service" not in st.session_state:
        st.session_state["model_service"] = None

    if "qianfan_authorization" not in st.session_state:
        st.session_state["qianfan_authorization"] = ""

    if "qianfan_model" not in st.session_state:
        st.session_state["qianfan_model"] = "ernie-4.5-turbo-vl-32k"

    if "ollama_host" not in st.session_state:
        st.session_state["ollama_host"] = "http://127.0.0.1:11434"

    if "ollama_model" not in st.session_state:
        st.session_state["ollama_model"] = "deepseek-r1:7b"


def load_available_models():
    """åŠ è½½å¯ç”¨çš„Ollamaæ¨¡å‹"""
    try:
        client = ollama.Client()
        models = client.list()
        return [model['name'] for model in models['models']]
    except Exception as e:
        st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []


def init_model_service():
    """åˆå§‹åŒ–æ¨¡å‹æœåŠ¡"""
    try:
        service_type = st.session_state["model_service_type"]

        if service_type == "qianfan":
            # åˆå§‹åŒ–åƒå¸†æœåŠ¡
            authorization = st.session_state["qianfan_authorization"]
            model = st.session_state["qianfan_model"]

            if not authorization:
                st.error("è¯·è®¾ç½®åƒå¸†æˆæƒä»¤ç‰Œ")
                return None

            st.session_state["model_service"] = create_model_service(
                "qianfan",
                authorization=authorization,
                model=model
            )

        elif service_type == "ollama":
            # åˆå§‹åŒ–OllamaæœåŠ¡
            host = st.session_state["ollama_host"]
            model = st.session_state["ollama_model"]

            st.session_state["model_service"] = create_model_service(
                "ollama",
                host=host,
                model=model
            )

        return st.session_state["model_service"]

    except Exception as e:
        st.error(f"åˆå§‹åŒ–æ¨¡å‹æœåŠ¡å¤±è´¥: {e}")
        return None


def show_model_service_config():
    """æ˜¾ç¤ºæ¨¡å‹æœåŠ¡é…ç½®"""
    st.subheader("ğŸ¤– æ¨¡å‹æœåŠ¡é…ç½®")

    # æœåŠ¡ç±»å‹é€‰æ‹©
    service_type = st.selectbox(
        "é€‰æ‹©æ¨¡å‹æœåŠ¡",
        ["qianfan", "ollama"],
        index=0 if st.session_state["model_service_type"] == "qianfan" else 1,
        help="é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹æœåŠ¡ç±»å‹"
    )

    if service_type != st.session_state["model_service_type"]:
        st.session_state["model_service_type"] = service_type
        st.session_state["model_service"] = None  # é‡ç½®æ¨¡å‹æœåŠ¡

    if service_type == "qianfan":
        # åƒå¸†é…ç½®
        st.write("**ç™¾åº¦åƒå¸†é…ç½®**")

        # ä»ç¯å¢ƒå˜é‡æˆ–ç”¨æˆ·è¾“å…¥è·å–æˆæƒä»¤ç‰Œ
        env_auth = os.environ.get("QIANFAN_AUTHORIZATION", "")
        authorization = st.text_input(
            "æˆæƒä»¤ç‰Œ (Authorization)",
            value=st.session_state.get("qianfan_authorization", "") or env_auth,
            type="password",
            help="è¯·è¾“å…¥åƒå¸†APIçš„æˆæƒä»¤ç‰Œï¼Œæ ¼å¼å¦‚ï¼šBearer bce-v3/xxx"
        )
        st.session_state["qianfan_authorization"] = authorization

        # æ¨¡å‹é€‰æ‹©
        qianfan_models = [
            "ernie-4.5-turbo-vl-32k",
            "ernie-4.0-turbo-8k",
            "ernie-3.5-8k",
            "ernie-lite-8k"
        ]
        model = st.selectbox(
            "åƒå¸†æ¨¡å‹",
            qianfan_models,
            index=qianfan_models.index(st.session_state.get("qianfan_model", "ernie-4.5-turbo-vl-32k"))
            if st.session_state.get("qianfan_model", "ernie-4.5-turbo-vl-32k") in qianfan_models else 0
        )
        st.session_state["qianfan_model"] = model

        # æ˜¾ç¤ºç½‘ç»œé…ç½®æç¤º
        st.info("ğŸ’¡ å¦‚æœé‡åˆ°ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š\n"
                "1. ç½‘ç»œä»£ç†è®¾ç½®\n"
                "2. é˜²ç«å¢™é…ç½®\n"
                "3. æˆæƒä»¤ç‰Œæ ¼å¼æ˜¯å¦æ­£ç¡®")

        # æµ‹è¯•è¿æ¥
        if st.button("æµ‹è¯•åƒå¸†è¿æ¥"):
            if authorization:
                try:
                    with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                        service = create_model_service("qianfan", authorization=authorization, model=model)
                        # å‘é€æµ‹è¯•æ¶ˆæ¯
                        test_messages = [{"role": "user", "content": "ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'"}]
                        response = service.chat(test_messages)

                        if "choices" in response and len(response["choices"]) > 0:
                            st.success("âœ… åƒå¸†æœåŠ¡è¿æ¥æˆåŠŸï¼")
                            st.session_state["model_service"] = service
                            st.write(f"æµ‹è¯•å›å¤: {response['choices'][0]['message']['content']}")
                        else:
                            st.error("âŒ åƒå¸†æœåŠ¡å“åº”æ ¼å¼é”™è¯¯")

                except Exception as e:
                    st.error(f"âŒ åƒå¸†æœåŠ¡è¿æ¥å¤±è´¥: {e}")
                    st.write("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæˆæƒä»¤ç‰Œ")
            else:
                st.warning("è¯·å…ˆè¾“å…¥æˆæƒä»¤ç‰Œ")

    elif service_type == "ollama":
        # Ollamaé…ç½®
        st.write("**Ollamaé…ç½®**")

        host = st.text_input(
            "OllamaæœåŠ¡å™¨åœ°å€",
            value=st.session_state.get("ollama_host", "http://127.0.0.1:11434"),
            help="OllamaæœåŠ¡å™¨çš„åœ°å€å’Œç«¯å£"
        )
        st.session_state["ollama_host"] = host

        # è·å–å¯ç”¨æ¨¡å‹
        try:
            available_models = load_available_models()
            if available_models:
                model = st.selectbox(
                    "Ollamaæ¨¡å‹",
                    available_models,
                    index=available_models.index(st.session_state.get("ollama_model", "deepseek-r1:7b"))
                    if st.session_state.get("ollama_model", "deepseek-r1:7b") in available_models else 0
                )
                st.session_state["ollama_model"] = model
                st.session_state["selected_model"] = model  # ä¿æŒå‘åå…¼å®¹
            else:
                st.error("æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹ï¼Œè¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ")
        except Exception as e:
            st.error(f"è¿æ¥OllamaæœåŠ¡å¤±è´¥: {e}")

        # æµ‹è¯•è¿æ¥
        if st.button("æµ‹è¯•Ollamaè¿æ¥"):
            try:
                with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                    service = create_model_service("ollama", host=host,
                                                   model=st.session_state.get("ollama_model", "deepseek-r1:7b"))
                    # å‘é€æµ‹è¯•æ¶ˆæ¯
                    test_messages = [{"role": "user", "content": "ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'"}]
                    response = service.chat(test_messages)

                    st.success("âœ… OllamaæœåŠ¡è¿æ¥æˆåŠŸï¼")
                    st.session_state["model_service"] = service
            except Exception as e:
                st.error(f"âŒ OllamaæœåŠ¡è¿æ¥å¤±è´¥: {e}")


def test_rag_system():
    """æµ‹è¯•RAGç³»ç»ŸåŠŸèƒ½"""
    st.subheader("ğŸ§ª RAGç³»ç»Ÿæµ‹è¯•")

    if 'rag_system' not in st.session_state:
        st.error("RAGç³»ç»Ÿæœªåˆå§‹åŒ–")
        return

    rag_system = st.session_state.rag_system

    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    stats = rag_system.get_document_stats()

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ“š æ–‡æ¡£æ•°é‡", len(stats['files']))
    with col2:
        st.metric("ğŸ“„ æ–‡æ¡£å—æ•°é‡", stats['total_chunks'])
    with col3:
        st.metric("ğŸ”‘ å…³é”®è¯æ•°é‡", stats['total_keywords'])

    if stats['total_chunks'] == 0:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£ï¼Œç„¶åå†è¿›è¡Œæµ‹è¯•")
        return

    # æµ‹è¯•æŸ¥è¯¢
    st.subheader("ğŸ” æ£€ç´¢æµ‹è¯•")
    test_query = st.text_input("è¾“å…¥æµ‹è¯•æŸ¥è¯¢", placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")

    if test_query:
        with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£..."):
            results = rag_system.search_documents(test_query, top_k=5)

            if results:
                st.success(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£å—")

                for i, result in enumerate(results):
                    with st.expander(f"ç»“æœ {i + 1} - {result['filename']} (ç›¸å…³æ€§: {result['relevance_score']:.2f})"):
                        st.write("**å†…å®¹é¢„è§ˆ:**")
                        st.write(result['content'][:300] + "..." if len(result['content']) > 300 else result['content'])

                        st.write("**å…³é”®è¯:**")
                        st.write(", ".join(result['keywords'][:10]))
            else:
                st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

    # æµ‹è¯•æ¨¡å‹æœåŠ¡ä¸RAGé›†æˆ
    st.subheader("ğŸ¤– æ¨¡å‹æœåŠ¡ä¸RAGé›†æˆæµ‹è¯•")

    if st.session_state.get("model_service") and test_query:
        if st.button("æµ‹è¯•RAGå¢å¼ºå›ç­”"):
            with st.spinner("æ­£åœ¨ç”ŸæˆRAGå¢å¼ºå›ç­”..."):
                try:
                    # æœç´¢ç›¸å…³æ–‡æ¡£
                    relevant_chunks = rag_system.search_documents(test_query, top_k=3)

                    if relevant_chunks:
                        # ç”ŸæˆRAGå¢å¼ºçš„æç¤ºè¯
                        enhanced_prompt = rag_system.generate_rag_prompt(test_query, relevant_chunks)

                        # æ„å»ºæ¶ˆæ¯
                        messages = [{"role": "user", "content": enhanced_prompt}]

                        # ä½¿ç”¨æ¨¡å‹æœåŠ¡ç”Ÿæˆå›ç­”
                        response = st.session_state["model_service"].chat(messages)

                        if "choices" in response and len(response["choices"]) > 0:
                            answer = response["choices"][0]["message"]["content"]
                            st.success("âœ… RAGå¢å¼ºå›ç­”ç”ŸæˆæˆåŠŸï¼")
                            st.write("**å›ç­”:**")
                            st.write(answer)

                            # æ˜¾ç¤ºä½¿ç”¨çš„æ–‡æ¡£ç‰‡æ®µ
                            with st.expander("ğŸ“š å‚è€ƒæ–‡æ¡£ç‰‡æ®µ"):
                                for i, chunk in enumerate(relevant_chunks):
                                    st.write(f"**ç‰‡æ®µ {i + 1}** ({chunk['filename']}):")
                                    st.write(chunk['content'][:200] + "..." if len(chunk['content']) > 200 else chunk[
                                        'content'])
                                    st.write("---")
                        else:
                            st.error("æ¨¡å‹å“åº”æ ¼å¼é”™è¯¯")
                    else:
                        st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œæ— æ³•è¿›è¡ŒRAGå¢å¼º")

                except Exception as e:
                    st.error(f"RAGå¢å¼ºå›ç­”ç”Ÿæˆå¤±è´¥: {e}")
                    import traceback
                    st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

def show_system_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€ä¿¡æ¯"""
    st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")

    # æ¨¡å‹æœåŠ¡çŠ¶æ€
    col1, col2 = st.columns(2)

    with col1:
        st.write("**æ¨¡å‹æœåŠ¡çŠ¶æ€:**")
        service_status = {
            "æœåŠ¡ç±»å‹": st.session_state.get("model_service_type", "æœªè®¾ç½®"),
            "æœåŠ¡çŠ¶æ€": "å·²è¿æ¥" if st.session_state.get("model_service") else "æœªè¿æ¥",
        }

        if st.session_state["model_service_type"] == "qianfan":
            service_status["æ¨¡å‹"] = st.session_state.get("qianfan_model", "æœªè®¾ç½®")
            service_status["æˆæƒçŠ¶æ€"] = "å·²è®¾ç½®" if st.session_state.get("qianfan_authorization") else "æœªè®¾ç½®"

        elif st.session_state["model_service_type"] == "ollama":
            service_status["ä¸»æœº"] = st.session_state.get("ollama_host", "æœªè®¾ç½®")
            service_status["æ¨¡å‹"] = st.session_state.get("ollama_model", "æœªè®¾ç½®")

        st.json(service_status)

    # RAGç³»ç»ŸçŠ¶æ€
    with col2:
        if 'rag_system' in st.session_state:
            rag_stats = st.session_state.rag_system.get_document_stats()
            st.write("**RAGç³»ç»ŸçŠ¶æ€:**")
            st.json({
                "æ–‡æ¡£æ•°é‡": len(rag_stats['files']),
                "æ–‡æ¡£å—æ•°é‡": rag_stats['total_chunks'],
                "å…³é”®è¯æ•°é‡": rag_stats['total_keywords'],
                "RAGçŠ¶æ€": "å·²å¯ç”¨" if st.session_state.get('use_rag', False) else "æœªå¯ç”¨"
            })

            st.write("**å·²å¤„ç†æ–‡æ¡£:**")
            if rag_stats['files']:
                for filename, chunk_count in rag_stats['files'].items():
                    st.write(f"â€¢ {filename}: {chunk_count} å—")
            else:
                st.write("æš‚æ— æ–‡æ¡£")

    # ä¼šè¯çŠ¶æ€
    st.write("**å½“å‰ä¼šè¯çŠ¶æ€:**")
    st.json({
        "æ¶ˆæ¯æ•°é‡": len(st.session_state.get("message", [])),
        "å½“å‰å¯¹è¯ID": st.session_state.get("current_conversation", 1),
        "æ¸©åº¦è®¾ç½®": st.session_state.get("temperature", 0.7),
        "æµå¼è¾“å‡º": st.session_state.get("use_stream", True)
    })


def chat_with_model_service(prompt, file_content=None):
    """ä½¿ç”¨æ¨¡å‹æœåŠ¡è¿›è¡Œå¯¹è¯"""
    if not st.session_state.get("model_service"):
        st.error("è¯·å…ˆé…ç½®å¹¶è¿æ¥æ¨¡å‹æœåŠ¡")
        return None

    try:
        # RAGå¢å¼ºæŸ¥è¯¢
        use_rag = st.session_state.get('use_rag', False)
        original_prompt = prompt
        relevant_chunks = []

        if use_rag and 'rag_system' in st.session_state:
            with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£..."):
                rag_system = st.session_state.rag_system
                relevant_chunks = rag_system.search_documents(prompt, top_k=st.session_state.get('top_k', 3))

                if relevant_chunks:
                    prompt = rag_system.generate_rag_prompt(prompt, relevant_chunks)
                    st.info(f"ğŸ” æ‰¾åˆ° {len(relevant_chunks)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")

        # å¤„ç†æ–‡ä»¶å†…å®¹
        if file_content:
            prompt = f"{file_content}\n\n{prompt}"

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""è§’è‰²è®¾å®šï¼š{st.session_state['role_config']}
åœºæ™¯è®¾å®šï¼š{st.session_state['scene_config']}
ä»»åŠ¡è¦æ±‚ï¼š{st.session_state['task_config']}

è¯·æ ¹æ®ä»¥ä¸Šè®¾å®šè¿›è¡Œå¯¹è¯ã€‚"""

        # æ„å»ºæ¶ˆæ¯å†å²
        messages = [{"role": "system", "content": system_prompt}]

        # æ·»åŠ å†å²æ¶ˆæ¯
        history_messages = st.session_state.get("message", [])[-st.session_state.get("maxHistoryMessages", 10):]
        messages.extend(history_messages)

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": prompt})

        # è°ƒç”¨æ¨¡å‹æœåŠ¡
        if st.session_state["model_service_type"] == "qianfan":
            # åƒå¸†æ¨¡å‹è°ƒç”¨
            response = st.session_state["model_service"].chat(
                messages,
                temperature=st.session_state.get("temperature", 0.7),
                stream=st.session_state.get("use_stream", False)
            )

            if st.session_state.get("use_stream", False):
                # åƒå¸†æµå¼å“åº”å¤„ç†
                if "choices" in response and len(response["choices"]) > 0:
                    return response["choices"][0]["message"]["content"]
                else:
                    st.error("æ¨¡å‹å“åº”æ ¼å¼é”™è¯¯")
                    return None
            else:
                if "choices" in response and len(response["choices"]) > 0:
                    return response["choices"][0]["message"]["content"]
                else:
                    st.error("æ¨¡å‹å“åº”æ ¼å¼é”™è¯¯")
                    return None

        elif st.session_state["model_service_type"] == "ollama":
            # å¯¹äºOllamaï¼Œä½¿ç”¨æ¨¡å‹æœåŠ¡çš„chatæ–¹æ³•
            if st.session_state.get("use_stream", False):
                # æµå¼è¾“å‡º
                assistant_message = ""
                assistant_message_placeholder = st.empty()

                # è°ƒç”¨ollamaå®¢æˆ·ç«¯è¿›è¡Œæµå¼è¾“å‡º
                import ollama
                client = ollama.Client(host=st.session_state["ollama_host"])

                response = client.chat(
                    model=st.session_state["ollama_model"],
                    messages=messages,
                    stream=True,
                    options={"temperature": st.session_state.get("temperature", 0.7)}
                )

                for chunk in response:
                    if chunk.get("message"):
                        assistant_message += chunk["message"]["content"]
                        assistant_message_placeholder.markdown(assistant_message)

                return assistant_message
            else:
                response = st.session_state["model_service"].chat(
                    messages,
                    temperature=st.session_state.get("temperature", 0.7),
                    stream=False
                )

                if "choices" in response and len(response["choices"]) > 0:
                    return response["choices"][0]["message"]["content"]
                else:
                    return response.get('message', {}).get('content', 'å“åº”æ ¼å¼é”™è¯¯')

    except Exception as e:
        st.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None


def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    init_session_state()

    # æ ‡é¢˜
    st.title("ğŸ¤– RAGå¢å¼ºæ™ºèƒ½å¯¹è¯ç³»ç»Ÿ")
    st.caption("æ”¯æŒå¤šç§æ¨¡å‹æœåŠ¡å’Œç§æœ‰æ–‡æ¡£æ£€ç´¢çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")

    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        # è¿”å›æŒ‰é’®
        if st.button("â† è¿”å›ä¸»ç•Œé¢"):
                st.switch_page("chatting_test.py")  # è·³å›ä¸»é¡µé¢
        # æ¨¡å‹æœåŠ¡é…ç½®
        show_model_service_config()

        # å¯¹è¯å‚æ•°è®¾ç½®
        st.divider()
        st.subheader("ğŸ’¬ å¯¹è¯å‚æ•°")
        st.session_state["temperature"] = st.slider(
            "æ¸©åº¦ (åˆ›é€ æ€§)",
            min_value=0.0,
            max_value=2.0,
            value=st.session_state["temperature"],
            step=0.1,
            help="è¾ƒä½å€¼ä½¿å›ç­”æ›´ç¡®å®šï¼Œè¾ƒé«˜å€¼ä½¿å›ç­”æ›´æœ‰åˆ›é€ æ€§"
        )

        st.session_state["use_stream"] = st.checkbox(
            "æµå¼è¾“å‡º",
            value=st.session_state["use_stream"],
            help="å¯ç”¨åå°†å®æ—¶æ˜¾ç¤ºå›ç­”è¿‡ç¨‹"
        )

        st.session_state["maxHistoryMessages"] = st.slider(
            "å†å²æ¶ˆæ¯æ•°é‡",
            min_value=2,
            max_value=50,
            value=st.session_state["maxHistoryMessages"],
            help="ä¿ç•™çš„å†å²æ¶ˆæ¯æ•°é‡"
        )

        # è§’è‰²è®¾å®š
        st.divider()
        st.subheader("ğŸ­ è§’è‰²è®¾å®š")
        st.session_state["role_config"] = st.text_area(
            "è§’è‰²æè¿°",
            value=st.session_state["role_config"],
            height=80,
            help="å®šä¹‰AIåŠ©æ‰‹çš„è§’è‰²å’Œæ€§æ ¼"
        )

        st.session_state["scene_config"] = st.text_area(
            "åœºæ™¯è®¾å®š",
            value=st.session_state["scene_config"],
            height=68,
            help="æè¿°å¯¹è¯çš„åœºæ™¯å’Œç¯å¢ƒ"
        )

        st.session_state["task_config"] = st.text_area(
            "ä»»åŠ¡è¦æ±‚",
            value=st.session_state["task_config"],
            height=80,
            help="æ˜ç¡®AIåŠ©æ‰‹éœ€è¦å®Œæˆçš„ä»»åŠ¡"
        )

        # # RAGè®¾ç½®
        # st.divider()
        # use_rag = show_rag_settings()
        #
        # # è°ƒè¯•é€‰é¡¹
        # st.subheader("ğŸ”§ è°ƒè¯•é€‰é¡¹")
        # st.session_state["show_rag_debug"] = st.checkbox(
        #     "æ˜¾ç¤ºRAGè°ƒè¯•ä¿¡æ¯",
        #     value=st.session_state.get("show_rag_debug", False),
        #     help="æ˜¾ç¤ºè¯¦ç»†çš„RAGæ£€ç´¢ä¿¡æ¯"
        # )

    # ä¸»ç•Œé¢æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ’¬ å¯¹è¯", "ğŸ“š æ–‡æ¡£ç®¡ç†", "ğŸ“ˆ å†å²è®°å½•", "ğŸ§ª ç³»ç»Ÿæµ‹è¯•", "ğŸ“Š çŠ¶æ€ç›‘æ§"])

    with tab1:
        # å¯¹è¯ç•Œé¢
        st.header("æ™ºèƒ½å¯¹è¯")

        if not st.session_state.get("model_service"):
            st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®å¹¶è¿æ¥æ¨¡å‹æœåŠ¡")
            return

        # æ–‡ä»¶ä¸Šä¼ ï¼ˆç”¨äºå•æ¬¡å¯¹è¯ï¼‰
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰",
            type=["txt", "pdf", "docx", "xlsx", "pptx"],
            help="ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹å°†ä½œä¸ºå¯¹è¯ä¸Šä¸‹æ–‡"
        )

        file_content = None
        if uploaded_file is not None:
            file_content = get_file_content(uploaded_file)
            if file_content:
                with st.expander("ğŸ“„ æ–‡ä»¶å†…å®¹é¢„è§ˆ"):
                    st.text_area("å†…å®¹", file_content[:500] + "..." if len(file_content) > 500 else file_content,
                                 height=200)

        # æ˜¾ç¤ºå¯¹è¯å†å²
        for message in st.session_state.get("message", []):
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # å¯¹è¯è¾“å…¥
        if prompt := st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜..."):
            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user"):
                st.markdown(prompt)

            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            st.session_state["message"].append({"role": "user", "content": prompt})

            # ç”ŸæˆåŠ©æ‰‹å›å¤
            with st.chat_message("assistant"):
                response = chat_with_model_service(prompt, file_content)
                if response:
                    st.markdown(response)
                    # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                    st.session_state["message"].append({"role": "assistant", "content": response})

        # æ¸…ç©ºå¯¹è¯æŒ‰é’®
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", type="secondary"):
                st.session_state["message"] = []
                st.rerun()

        with col2:
            if st.button("ğŸ”„ æ–°å»ºå¯¹è¯", type="primary"):
                st.session_state["message"] = []
                st.session_state["current_conversation"] += 1
                st.rerun()

    with tab2:
        # æ–‡æ¡£ç®¡ç†ç•Œé¢
        st.header("ç§æœ‰æ–‡æ¡£ç®¡ç†")
        show_rag_management()

        # RAGå‚æ•°è°ƒæ•´
        st.subheader("ğŸ”§ RAGå‚æ•°è°ƒæ•´")
        col1, col2 = st.columns(2)

        with col1:
            new_chunk_size = st.slider(
                "æ–‡æ¡£åˆ†å—å¤§å°",
                min_value=200,
                max_value=1000,
                value=st.session_state.get('chunk_size', 500),
                step=50,
                help="è°ƒæ•´åéœ€è¦é‡æ–°å¤„ç†æ–‡æ¡£"
            )

        with col2:
            new_top_k = st.slider(
                "æ£€ç´¢æ–‡æ¡£æ•°é‡",
                min_value=1,
                max_value=10,
                value=st.session_state.get('top_k', 3),
                help="æ¯æ¬¡æŸ¥è¯¢è¿”å›çš„ç›¸å…³æ–‡æ¡£å—æ•°é‡"
            )

        # æ£€æŸ¥å‚æ•°æ˜¯å¦æ”¹å˜
        if (new_chunk_size != st.session_state.get('chunk_size', 500) or
                new_top_k != st.session_state.get('top_k', 3)):

            st.session_state['chunk_size'] = new_chunk_size
            st.session_state['top_k'] = new_top_k

            # æ›´æ–°RAGç³»ç»Ÿå‚æ•°
            if 'rag_system' in st.session_state:
                st.session_state.rag_system.processor.chunk_size = new_chunk_size
                st.info("å‚æ•°å·²æ›´æ–°ï¼Œå»ºè®®é‡æ–°å¤„ç†æ–‡æ¡£ä»¥è·å¾—æœ€ä½³æ•ˆæœ")

    with tab3:
        # å†å²è®°å½•ç•Œé¢
        st.header("å¯¹è¯å†å²")
        try:
            show_conversation_history()
        except Exception as e:
            st.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
            st.info("è¯·ç¡®ä¿å†å²è®°å½•æœåŠ¡æ­£å¸¸è¿è¡Œ")

    with tab4:
        # ç³»ç»Ÿæµ‹è¯•ç•Œé¢
        st.header("ç³»ç»ŸåŠŸèƒ½æµ‹è¯•")
        test_rag_system()

        # RAGè°ƒè¯•ä¿¡æ¯
        if st.session_state.get("show_rag_debug", False):
            show_rag_debug_info()

    with tab5:
        # çŠ¶æ€ç›‘æ§ç•Œé¢
        st.header("ç³»ç»ŸçŠ¶æ€ç›‘æ§")
        show_system_status()

        # æ€§èƒ½ç›‘æ§
        st.subheader("ğŸ“ˆ æ€§èƒ½ç›‘æ§")

        if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€"):
            st.rerun()

        # ç³»ç»Ÿå¥åº·æ£€æŸ¥
        st.subheader("ğŸ¥ ç³»ç»Ÿå¥åº·æ£€æŸ¥")

        col1, col2, col3 = st.columns(3)

        with col1:
            # æ¨¡å‹æœåŠ¡æ£€æŸ¥
            if st.session_state.get("model_service"):
                st.success("âœ… æ¨¡å‹æœåŠ¡æ­£å¸¸")
            else:
                st.error("âŒ æ¨¡å‹æœåŠ¡æœªè¿æ¥")

        with col2:
            # RAGç³»ç»Ÿæµ‹è¯•
            if 'rag_system' in st.session_state:
                stats = st.session_state.rag_system.get_document_stats()
                if stats['total_chunks'] > 0:
                    st.success("âœ… RAGç³»ç»Ÿæ­£å¸¸")
                else:
                    st.warning("âš ï¸ RAGç³»ç»Ÿæ— æ–‡æ¡£")
            else:
                st.error("âŒ RAGç³»ç»Ÿæœªåˆå§‹åŒ–")

        with col3:
            # ä¼šè¯çŠ¶æ€æµ‹è¯•
            if st.session_state.get("message"):
                st.success("âœ… ä¼šè¯çŠ¶æ€æ­£å¸¸")
            else:
                st.info("â„¹ï¸ æš‚æ— ä¼šè¯å†å²")


if __name__ == "__main__":
    main()
