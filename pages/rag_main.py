import streamlit as st
from modules.rag_module import show_rag_management, RAGSystem
from modules.enhanced_conversation_display import (
    display_rag_enhanced_conversation,
    show_rag_debug_info
)
from modules.file_processing import get_file_content
from modules.history_module import show_conversation_history
from modules.model_service import create_model_service, ModelService, QianfanModelService
import os

# é¡µé¢é…ç½®
#éšè—è‡ªåŠ¨å¯¼èˆª2
st.markdown("""
<style>
    [data-testid="stSidebarNav"] {
        display: none !important;
    }
</style>
""", unsafe_allow_html=True)



# åˆå§‹åŒ–session state
def init_session_state():
    """åˆå§‹åŒ–session stateå˜é‡"""
    if "message" not in st.session_state:
        st.session_state["message"] = []

    if "current_conversation" not in st.session_state:
        st.session_state["current_conversation"] = 1

    if "show_history" not in st.session_state:
        st.session_state["show_history"] = False

    if "temperature" not in st.session_state:
        st.session_state["temperature"] = 0.7

    if "role_config" not in st.session_state:
        st.session_state["role_config"] = "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹"

    if "scene_config" not in st.session_state:
        st.session_state["scene_config"] = "æ—¥å¸¸å¯¹è¯åœºæ™¯"

    if "task_config" not in st.session_state:
        st.session_state["task_config"] = "å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæä¾›æœ‰ç”¨çš„ä¿¡æ¯"

    if "use_rag" not in st.session_state:
        st.session_state["use_rag"] = False

    if "rag_system" not in st.session_state:
        st.session_state["rag_system"] = RAGSystem()

    if "show_rag_debug" not in st.session_state:
        st.session_state["show_rag_debug"] = False

    if "chunk_size" not in st.session_state:
        st.session_state["chunk_size"] = 500

    if "top_k" not in st.session_state:
        st.session_state["top_k"] = 3

    if "selected_model" not in st.session_state:
        st.session_state["selected_model"] = ""

    if "use_stream" not in st.session_state:
        st.session_state["use_stream"] = False

    if "maxHistoryMessages" not in st.session_state:
        st.session_state["maxHistoryMessages"] = 10

    if "model_service_type" not in st.session_state:
        st.session_state["model_service_type"] = "qianfan"

    if "model_service" not in st.session_state:
        st.session_state["model_service"] = None

    if "qianfan_authorization" not in st.session_state:
        st.session_state["qianfan_authorization"] = ""

    if "qianfan_model" not in st.session_state:
        st.session_state["qianfan_model"] = "ernie-4.5-turbo-vl-32k"


def init_model_service():
    """åˆå§‹åŒ–æ¨¡å‹æœåŠ¡"""
    try:
        service_type = st.session_state["model_service_type"]
        if service_type == "qianfan":
            # åˆå§‹åŒ–åƒå¸†æœåŠ¡
            authorization = st.session_state["qianfan_authorization"]
            model = st.session_state["qianfan_model"]

            if not authorization:
                st.error("è¯·è®¾ç½®åƒå¸†æˆæƒä»¤ç‰Œ")
                return None

            st.session_state["model_service"] = create_model_service(
                "qianfan",
                authorization=authorization,
                model=model
            )



        return st.session_state["model_service"]

    except Exception as e:
        st.error(f"åˆå§‹åŒ–æ¨¡å‹æœåŠ¡å¤±è´¥: {e}")
        return None


def show_model_service_config():
    """æ˜¾ç¤ºæ¨¡å‹æœåŠ¡é…ç½®"""
    st.subheader("ğŸ¤– æ¨¡å‹æœåŠ¡é…ç½®")
    st.subheader("æ¨¡å‹æœåŠ¡:qianfan")
    # æœåŠ¡ç±»å‹é€‰æ‹©
    service_type = "qianfan"

    if service_type != st.session_state["model_service_type"]:
        st.session_state["model_service_type"] = service_type
        st.session_state["model_service"] = None  # é‡ç½®æ¨¡å‹æœåŠ¡

    if service_type == "qianfan":
        # åƒå¸†é…ç½®
        st.write("**ç™¾åº¦åƒå¸†é…ç½®**")

        # ä»ç¯å¢ƒå˜é‡æˆ–ç”¨æˆ·è¾“å…¥è·å–æˆæƒä»¤ç‰Œ
        env_auth = os.environ.get("QIANFAN_AUTHORIZATION", "")
        authorization = st.text_input(
            "æˆæƒä»¤ç‰Œ (Authorization)",
            value=st.session_state.get("qianfan_authorization", "") or env_auth,
            type="password",
            help="è¯·è¾“å…¥åƒå¸†APIçš„æˆæƒä»¤ç‰Œï¼Œæ ¼å¼å¦‚ï¼šBearer bce-v3/xxx"
        )
        st.session_state["qianfan_authorization"] = authorization

        # æ¨¡å‹é€‰æ‹©
        qianfan_models = [
            "ernie-4.5-turbo-vl-32k",
            "ernie-4.0-turbo-8k",
            "ernie-3.5-8k",
            "ernie-lite-8k"
        ]
        model = st.selectbox(
            "åƒå¸†æ¨¡å‹",
            qianfan_models,
            index=qianfan_models.index(st.session_state.get("qianfan_model", "ernie-4.5-turbo-vl-32k"))
            if st.session_state.get("qianfan_model", "ernie-4.5-turbo-vl-32k") in qianfan_models else 0
        )
        st.session_state["qianfan_model"] = model

        # æ˜¾ç¤ºç½‘ç»œé…ç½®æç¤º
        st.info("ğŸ’¡ å¦‚æœé‡åˆ°ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š\n"
                "1. ç½‘ç»œä»£ç†è®¾ç½®\n"
                "2. é˜²ç«å¢™é…ç½®\n"
                "3. æˆæƒä»¤ç‰Œæ ¼å¼æ˜¯å¦æ­£ç¡®")

        # æµ‹è¯•è¿æ¥
        if st.button("æµ‹è¯•åƒå¸†è¿æ¥"):
            if authorization:
                try:
                    with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                        service = create_model_service("qianfan", authorization=authorization, model=model)
                        # å‘é€æµ‹è¯•æ¶ˆæ¯
                        test_messages = [{"role": "user", "content": "ä½ å¥½ï¼Œè¯·å›å¤'è¿æ¥æˆåŠŸ'"}]
                        response = service.chat(test_messages)

                        if "choices" in response and len(response["choices"]) > 0:
                            st.success("âœ… åƒå¸†æœåŠ¡è¿æ¥æˆåŠŸï¼")
                            st.session_state["model_service"] = service
                            st.write(f"æµ‹è¯•å›å¤: {response['choices'][0]['message']['content']}")
                        else:
                            st.error("âŒ åƒå¸†æœåŠ¡å“åº”æ ¼å¼é”™è¯¯")

                except Exception as e:
                    st.error(f"âŒ åƒå¸†æœåŠ¡è¿æ¥å¤±è´¥: {e}")
                    st.write("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæˆæƒä»¤ç‰Œ")
            else:
                st.warning("è¯·å…ˆè¾“å…¥æˆæƒä»¤ç‰Œ")

def test_rag_system():
    """æµ‹è¯•RAGç³»ç»ŸåŠŸèƒ½"""
    st.subheader("ğŸ§ª RAGç³»ç»Ÿæµ‹è¯•")

    if 'rag_system' not in st.session_state:
        st.error("RAGç³»ç»Ÿæœªåˆå§‹åŒ–")
        return

    rag_system = st.session_state.rag_system

    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    stats = rag_system.get_document_stats()

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ“š æ–‡æ¡£æ•°é‡", len(stats['files']))
    with col2:
        st.metric("ğŸ“„ æ–‡æ¡£å—æ•°é‡", stats['total_chunks'])
    with col3:
        st.metric("ğŸ”‘ å…³é”®è¯æ•°é‡", stats['total_keywords'])

    if stats['total_chunks'] == 0:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£ï¼Œç„¶åå†è¿›è¡Œæµ‹è¯•")
        return

    # æµ‹è¯•æŸ¥è¯¢
    st.subheader("ğŸ” æ£€ç´¢æµ‹è¯•")
    test_query = st.text_input("è¾“å…¥æµ‹è¯•æŸ¥è¯¢", placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ")

    if test_query:
        with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£..."):
            results = rag_system.search_documents(test_query, top_k=5)

            if results:
                st.success(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£å—")

                for i, result in enumerate(results):
                    with st.expander(f"ç»“æœ {i + 1} - {result['filename']} (ç›¸å…³æ€§: {result['relevance_score']:.2f})"):
                        st.write("**å†…å®¹é¢„è§ˆ:**")
                        st.write(result['content'][:300] + "..." if len(result['content']) > 300 else result['content'])

                        st.write("**å…³é”®è¯:**")
                        st.write(", ".join(result['keywords'][:10]))
            else:
                st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

    # æµ‹è¯•æ¨¡å‹æœåŠ¡ä¸RAGé›†æˆ
    st.subheader("ğŸ¤– æ¨¡å‹æœåŠ¡ä¸RAGé›†æˆæµ‹è¯•")

    if st.session_state["model_service"] and test_query:
        if st.button("æµ‹è¯•RAGå¢å¼ºå›ç­”"):
            with st.spinner("æ­£åœ¨ç”ŸæˆRAGå¢å¼ºå›ç­”..."):
                try:
                    # æœç´¢ç›¸å…³æ–‡æ¡£
                    relevant_chunks = rag_system.search_documents(test_query, top_k=3)

                    if relevant_chunks:
                        # ç”ŸæˆRAGå¢å¼ºçš„æç¤ºè¯
                        enhanced_prompt = rag_system.generate_rag_prompt(test_query, relevant_chunks)

                        # æ„å»ºæ¶ˆæ¯
                        messages = [{"role": "user", "content": enhanced_prompt}]

                        with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                            # ä½¿ç”¨æ¨¡å‹æœåŠ¡ç”Ÿæˆå›ç­”
                            response = st.session_state["model_service"].chat(messages)

                        if "choices" in response and len(response["choices"]) > 0:
                            answer = response["choices"][0]["message"]["content"]
                            st.success("âœ… RAGå¢å¼ºå›ç­”ç”ŸæˆæˆåŠŸï¼")
                            st.write("**å›ç­”:**")
                            st.write(answer)

                            # æ˜¾ç¤ºä½¿ç”¨çš„æ–‡æ¡£ç‰‡æ®µ
                            with st.expander("ğŸ“š å‚è€ƒæ–‡æ¡£ç‰‡æ®µ"):
                                for i, chunk in enumerate(relevant_chunks):
                                    st.write(f"**ç‰‡æ®µ {i + 1}** ({chunk['filename']}):")
                                    st.write(chunk['content'][:200] + "..." if len(chunk['content']) > 200 else chunk[
                                        'content'])
                                    st.write("---")
                        else:
                            st.error("æ¨¡å‹å“åº”æ ¼å¼é”™è¯¯")
                    else:
                        st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œæ— æ³•è¿›è¡ŒRAGå¢å¼º")

                except Exception as e:
                    st.error(f"RAGå¢å¼ºå›ç­”ç”Ÿæˆå¤±è´¥: {e}")
                    import traceback
                    st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

def show_system_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€ä¿¡æ¯"""
    st.subheader("ğŸ“Š ç³»ç»ŸçŠ¶æ€")

    # æ¨¡å‹æœåŠ¡çŠ¶æ€
    col1, col2 = st.columns(2)

    with col1:
        st.write("**æ¨¡å‹æœåŠ¡çŠ¶æ€:**")
        service_status = {
            "æœåŠ¡ç±»å‹": st.session_state.get("model_service_type", "æœªè®¾ç½®"),
            "æœåŠ¡çŠ¶æ€": "å·²è¿æ¥" if st.session_state["model_service"] else "æœªè¿æ¥",
        }

        if st.session_state["model_service_type"] == "qianfan":
            service_status["æ¨¡å‹"] = st.session_state.get("qianfan_model", "æœªè®¾ç½®")
            service_status["æˆæƒçŠ¶æ€"] = "å·²è®¾ç½®" if st.session_state.get("qianfan_authorization") else "æœªè®¾ç½®"

        st.json(service_status)

    # RAGç³»ç»ŸçŠ¶æ€
    with col2:
        if 'rag_system' in st.session_state:
            rag_stats = st.session_state.rag_system.get_document_stats()
            st.write("**RAGç³»ç»ŸçŠ¶æ€:**")
            st.json({
                "æ–‡æ¡£æ•°é‡": len(rag_stats['files']),
                "æ–‡æ¡£å—æ•°é‡": rag_stats['total_chunks'],
                "å…³é”®è¯æ•°é‡": rag_stats['total_keywords'],
                "RAGçŠ¶æ€": "å·²å¯ç”¨" if st.session_state.get('use_rag', False) else "æœªå¯ç”¨"
            })

            st.write("**å·²å¤„ç†æ–‡æ¡£:**")
            if rag_stats['files']:
                for filename, chunk_count in rag_stats['files'].items():
                    st.write(f"â€¢ {filename}: {chunk_count} å—")
            else:
                st.write("æš‚æ— æ–‡æ¡£")

    # ä¼šè¯çŠ¶æ€
    st.write("**å½“å‰ä¼šè¯çŠ¶æ€:**")
    st.json({
        "æ¶ˆæ¯æ•°é‡": len(st.session_state.get("message", [])),
        "å½“å‰å¯¹è¯ID": st.session_state.get("current_conversation", 1),
        "æ¸©åº¦è®¾ç½®": st.session_state.get("temperature", 0.7),
        "æµå¼è¾“å‡º": st.session_state["use_stream"]
    })


def chat_with_model_service(prompt):
    """ä½¿ç”¨æ¨¡å‹æœåŠ¡è¿›è¡Œå¯¹è¯"""
    if not st.session_state["model_service"]:
        st.error("è¯·å…ˆé…ç½®å¹¶è¿æ¥æ¨¡å‹æœåŠ¡")
        return None

    # RAGå¢å¼ºæŸ¥è¯¢
    try:
        use_rag = st.session_state.get('use_rag', False)
        original_prompt = prompt
        relevant_chunks = []

        if use_rag and 'rag_system' in st.session_state:
            with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£..."):
                rag_system = st.session_state.rag_system
                relevant_chunks = rag_system.search_documents(prompt, top_k=st.session_state.get('top_k', 3))

                if relevant_chunks:
                    prompt = rag_system.generate_rag_prompt(prompt, relevant_chunks)
                    st.info(f"ğŸ” æ‰¾åˆ° {len(relevant_chunks)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")

        # å¤„ç†æ–‡ä»¶å†…å®¹

        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""è§’è‰²è®¾å®šï¼š{st.session_state['role_config']}
åœºæ™¯è®¾å®šï¼š{st.session_state['scene_config']}
ä»»åŠ¡è¦æ±‚ï¼š{st.session_state['task_config']}

è¯·æ ¹æ®ä»¥ä¸Šè®¾å®šè¿›è¡Œå¯¹è¯ã€‚"""

        # æ„å»ºæ¶ˆæ¯å†å²
        messages = [{"role": "system", "content": system_prompt}]

        # æ·»åŠ å†å²æ¶ˆæ¯
        history_messages = st.session_state.get("message", [])[-st.session_state.get("maxHistoryMessages", 10):]
        messages.extend(history_messages)

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": prompt})

        # è°ƒç”¨æ¨¡å‹æœåŠ¡
        if st.session_state["model_service_type"] == "qianfan":
            # åƒå¸†æ¨¡å‹è°ƒç”¨
            response = st.session_state["model_service"].chat(
                messages,
                temperature=st.session_state.get("temperature", 0.7),
                stream=st.session_state["use_stream"]
            )



    except Exception as e:
        st.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return None


def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    init_session_state()

    # æ ‡é¢˜
    st.title("ğŸ¤– RAGå¢å¼ºæ™ºèƒ½å¯¹è¯ç³»ç»Ÿ")
    st.caption("æ”¯æŒå¤šç§æ¨¡å‹æœåŠ¡å’Œç§æœ‰æ–‡æ¡£æ£€ç´¢çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")

    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        # è¿”å›æŒ‰é’®
        if st.button("â† è¿”å›ä¸»ç•Œé¢"):
                st.switch_page("chatting_test.py")  # è·³å›ä¸»é¡µé¢
        # æ¨¡å‹æœåŠ¡é…ç½®
        show_model_service_config()

        # å¯¹è¯å‚æ•°è®¾ç½®
        st.divider()
        st.subheader("ğŸ’¬ å¯¹è¯å‚æ•°")
        st.session_state["temperature"] = st.slider(
            "æ¸©åº¦ (åˆ›é€ æ€§)",
            min_value=0.0,
            max_value=2.0,
            value=st.session_state["temperature"],
            step=0.1,
            help="è¾ƒä½å€¼ä½¿å›ç­”æ›´ç¡®å®šï¼Œè¾ƒé«˜å€¼ä½¿å›ç­”æ›´æœ‰åˆ›é€ æ€§"
        )

        st.session_state["use_stream"] = False

        st.session_state["maxHistoryMessages"] = st.slider(
            "å†å²æ¶ˆæ¯æ•°é‡",
            min_value=2,
            max_value=50,
            value=st.session_state["maxHistoryMessages"],
            help="ä¿ç•™çš„å†å²æ¶ˆæ¯æ•°é‡"
        )

        # è§’è‰²è®¾å®š
        st.divider()
        st.subheader("ğŸ­ è§’è‰²è®¾å®š")
        st.session_state["role_config"] = st.text_area(
            "è§’è‰²æè¿°",
            value=st.session_state["role_config"],
            height=80,
            help="å®šä¹‰AIåŠ©æ‰‹çš„è§’è‰²å’Œæ€§æ ¼"
        )

        st.session_state["scene_config"] = st.text_area(
            "åœºæ™¯è®¾å®š",
            value=st.session_state["scene_config"],
            height=68,
            help="æè¿°å¯¹è¯çš„åœºæ™¯å’Œç¯å¢ƒ"
        )

        st.session_state["task_config"] = st.text_area(
            "ä»»åŠ¡è¦æ±‚",
            value=st.session_state["task_config"],
            height=80,
            help="æ˜ç¡®AIåŠ©æ‰‹éœ€è¦å®Œæˆçš„ä»»åŠ¡"
        )



    # ä¸»ç•Œé¢æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ å¯¹è¯", "ğŸ“š æ–‡æ¡£ç®¡ç†", "ğŸ§ª ç³»ç»Ÿæµ‹è¯•", "ğŸ“Š çŠ¶æ€ç›‘æ§"])




    with tab1:

        # å¯¹è¯ç•Œé¢
        st.header("æ™ºèƒ½å¯¹è¯")

        if not st.session_state["model_service"]:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®å¹¶è¿æ¥æ¨¡å‹æœåŠ¡")
            return

        rag_system = st.session_state.rag_system
        stats = rag_system.get_document_stats()
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“š æ–‡æ¡£æ•°é‡", len(stats['files']))
        with col2:
            st.metric("ğŸ“„ æ–‡æ¡£å—æ•°é‡", stats['total_chunks'])
        with col3:
            st.metric("ğŸ”‘ å…³é”®è¯æ•°é‡", stats['total_keywords'])
        # æ˜¾ç¤ºå¯¹è¯å†å²
        # for message in st.session_state.get("message", []):
        #     with st.chat_message(message["role"]):
        #         st.markdown(message["content"])

        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", type="secondary"):
            st.session_state["message"] = []
            st.rerun()

        test_query = st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜...")
        if test_query:
            try:
                # æœç´¢ç›¸å…³æ–‡æ¡£
                relevant_chunks = rag_system.search_documents(test_query, top_k=3)

                if relevant_chunks:
                    # ç”ŸæˆRAGå¢å¼ºçš„æç¤ºè¯
                    enhanced_prompt = rag_system.generate_rag_prompt(test_query, relevant_chunks)

                    # æ„å»ºæ¶ˆæ¯
                    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆä»…æ˜¾ç¤ºæé—®éƒ¨åˆ†ï¼‰
                    user_message = {"role": "user", "content": enhanced_prompt,"original_question": test_query}
                    st.session_state["message"].append(user_message)

                    #æ˜¾ç¤ºå…ˆå‰æ¶ˆæ¯
                    for message in st.session_state["message"]:
                        if message["role"] == "user":
                            content = message["original_question"]
                            content = content.split("ç”¨æˆ·æé—®ï¼š")[-1]
                        else:
                            content = message["content"]
                        st.chat_message(message["role"]).markdown(content)

                    # ä½¿ç”¨æ¨¡å‹æœåŠ¡ç”Ÿæˆå›ç­”
                    response = st.session_state["model_service"].chat(st.session_state["message"])

                    if "choices" in response and len(response["choices"]) > 0:
                        answer = response["choices"][0]["message"]["content"]
                        st.success("âœ… RAGå¢å¼ºå›ç­”ç”ŸæˆæˆåŠŸï¼")
                        st.write("**å›ç­”:**")
                        st.write(answer)

                        assistant_message = {"role": "assistant", "content": answer}
                        st.session_state["message"].append(assistant_message)

                        # æ˜¾ç¤ºä½¿ç”¨çš„æ–‡æ¡£ç‰‡æ®µ
                        with st.expander("ğŸ“š å‚è€ƒæ–‡æ¡£ç‰‡æ®µ"):
                            for i, chunk in enumerate(relevant_chunks):
                                st.write(f"**ç‰‡æ®µ {i + 1}** ({chunk['filename']}):")
                                st.write(chunk['content'][:200] + "..." if len(chunk['content']) > 200 else chunk[
                                    'content'])
                                st.write("---")
                    else:
                        st.error("æ¨¡å‹å“åº”æ ¼å¼é”™è¯¯")
                else:
                    st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œæ— æ³•è¿›è¡ŒRAGå¢å¼º")

            except Exception as e:
                st.error(f"RAGå¢å¼ºå›ç­”ç”Ÿæˆå¤±è´¥: {e}")
                import traceback
                st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

    with tab2:



        # æ–‡æ¡£ç®¡ç†ç•Œé¢
        st.header("ç§æœ‰æ–‡æ¡£ç®¡ç†")
        show_rag_management()

        # RAGå‚æ•°è°ƒæ•´
        st.subheader("ğŸ”§ RAGå‚æ•°è°ƒæ•´")
        col1, col2 = st.columns(2)

        with col1:
            new_chunk_size = st.slider(
                "æ–‡æ¡£åˆ†å—å¤§å°",
                min_value=200,
                max_value=1000,
                value=st.session_state.get('chunk_size', 500),
                step=50,
                help="è°ƒæ•´åéœ€è¦é‡æ–°å¤„ç†æ–‡æ¡£"
            )

        with col2:
            new_top_k = st.slider(
                "æ£€ç´¢æ–‡æ¡£æ•°é‡",
                min_value=1,
                max_value=10,
                value=st.session_state.get('top_k', 3),
                help="æ¯æ¬¡æŸ¥è¯¢è¿”å›çš„ç›¸å…³æ–‡æ¡£å—æ•°é‡"
            )

        # æ£€æŸ¥å‚æ•°æ˜¯å¦æ”¹å˜
        if (new_chunk_size != st.session_state.get('chunk_size', 500) or
                new_top_k != st.session_state.get('top_k', 3)):

            st.session_state['chunk_size'] = new_chunk_size
            st.session_state['top_k'] = new_top_k

            # æ›´æ–°RAGç³»ç»Ÿå‚æ•°
            if 'rag_system' in st.session_state:
                st.session_state.rag_system.processor.chunk_size = new_chunk_size
                st.info("å‚æ•°å·²æ›´æ–°ï¼Œå»ºè®®é‡æ–°å¤„ç†æ–‡æ¡£ä»¥è·å¾—æœ€ä½³æ•ˆæœ")

    with tab3:

        # ç³»ç»Ÿæµ‹è¯•ç•Œé¢
        st.header("ç³»ç»ŸåŠŸèƒ½æµ‹è¯•")
        test_rag_system()

        # RAGè°ƒè¯•ä¿¡æ¯
        if st.session_state.get("show_rag_debug", False):
            show_rag_debug_info()

    with tab4:

        # çŠ¶æ€ç›‘æ§ç•Œé¢
        st.header("ç³»ç»ŸçŠ¶æ€ç›‘æ§")
        show_system_status()

        # æ€§èƒ½ç›‘æ§
        st.subheader("ğŸ“ˆ æ€§èƒ½ç›‘æ§")

        if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€"):
            st.rerun()

        # ç³»ç»Ÿå¥åº·æ£€æŸ¥
        st.subheader("ğŸ¥ ç³»ç»Ÿå¥åº·æ£€æŸ¥")

        col1, col2, col3 = st.columns(3)

        with col1:
            # æ¨¡å‹æœåŠ¡æ£€æŸ¥
            if st.session_state["model_service"]:
                st.success("âœ… æ¨¡å‹æœåŠ¡æ­£å¸¸")
            else:
                st.error("âŒ æ¨¡å‹æœåŠ¡æœªè¿æ¥")

        with col2:
            # RAGç³»ç»Ÿæµ‹è¯•
            if 'rag_system' in st.session_state:
                stats = st.session_state.rag_system.get_document_stats()
                if stats['total_chunks'] > 0:
                    st.success("âœ… RAGç³»ç»Ÿæ­£å¸¸")
                else:
                    st.warning("âš ï¸ RAGç³»ç»Ÿæ— æ–‡æ¡£")
            else:
                st.error("âŒ RAGç³»ç»Ÿæœªåˆå§‹åŒ–")

        with col3:
            # ä¼šè¯çŠ¶æ€æµ‹è¯•
            if st.session_state.get("message"):
                st.success("âœ… ä¼šè¯çŠ¶æ€æ­£å¸¸")
            else:
                st.info("â„¹ï¸ æš‚æ— ä¼šè¯å†å²")


if __name__ == "__main__":
    main()
