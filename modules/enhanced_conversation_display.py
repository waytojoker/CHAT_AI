import time
import re
import streamlit as st
import requests
from modules.file_processing import read_file
from modules.rag_module import enhance_query_with_rag


def preprocess_output(output):
    # æ›¿æ¢ $$...$$ åŒ…è£¹çš„å…¬å¼ä¸º st.latex å¯è¯†åˆ«çš„å½¢å¼
    # ä¾‹å¦‚ï¼š$$\boxed{8}$$ â†’ \boxed{8}
    output = output.replace("<think>", "\n\n**æ€è€ƒï¼š**\n")
    output = output.replace("</think>", "\n\n**å›ç­”ï¼š**\n")
    output = re.sub(r"\$\$(.*?)\$\$", r"$$\1$$", output)
    output = re.sub(r"\\boxed\{(.*?)\}", r"\1", output)
    return output


def get_system_prompt():
    """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
    return f"""è§’è‰²è®¾å®šï¼š{st.session_state['role_config']}

åœºæ™¯è®¾å®šï¼š{st.session_state['scene_config']}

ä»»åŠ¡è¦æ±‚ï¼š{st.session_state['task_config']}

è¯·æ ¹æ®ä»¥ä¸Šè®¾å®šè¿›è¡Œå¯¹è¯ã€‚"""


def display_conversation(prompt, file_content, client, selected_model, use_stream, maxHistoryMessages,
                         conversation_id=1, user_id=1, use_rag=False):
    """
    å°è£…å¯¹è¯å±•ç¤ºé€»è¾‘ï¼Œé›†æˆRAGåŠŸèƒ½ã€‚
    """
    original_prompt = prompt

    # RAGå¢å¼ºæŸ¥è¯¢
    if use_rag:
        with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£..."):
            enhanced_prompt, relevant_chunks = enhance_query_with_rag(prompt, use_rag)

            # æ˜¾ç¤ºæœç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£
            if relevant_chunks:
                st.info(f"ğŸ” æ‰¾åˆ° {len(relevant_chunks)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")

                # åœ¨ä¾§è¾¹æ æ˜¾ç¤ºç›¸å…³æ–‡æ¡£è¯¦æƒ…
                with st.sidebar:
                    st.subheader("ğŸ“„ ç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
                    for i, chunk in enumerate(relevant_chunks):
                        with st.expander(
                                f"ç‰‡æ®µ {i + 1} - {chunk['filename']} (ç›¸å…³æ€§: {chunk['relevance_score']:.2f})"):
                            st.write(
                                chunk['content'][:300] + "..." if len(chunk['content']) > 300 else chunk['content'])

                prompt = enhanced_prompt
            else:
                st.warning("ğŸ” æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ç‰‡æ®µï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢")

    # å¤„ç†æ–‡ä»¶å†…å®¹
    if file_content is not None:
        prompt = file_content + prompt

    full_prompt = f"{file_content}\n\nç”¨æˆ·æé—®ï¼š{original_prompt}" if file_content else f"ç”¨æˆ·æé—®ï¼š{original_prompt}"

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ˜¾ç¤ºåŸå§‹æé—®ï¼‰
    user_message = {"role": "user", "content": original_prompt}
    st.session_state["message"].append(user_message)

    # æ˜¾ç¤ºå…ˆå‰æ¶ˆæ¯
    for message in st.session_state["message"]:
        content = message["content"]
        if message["role"] == "user" and "ç”¨æˆ·æé—®ï¼š" in content:
            content = content.split("ç”¨æˆ·æé—®ï¼š")[-1]
        st.chat_message(message["role"]).markdown(content)

    # è·å– Ollama çš„å›å¤
    with st.spinner("æ­£åœ¨æ€è€ƒ..."):
        system_message = {"role": "system", "content": get_system_prompt()}
        user_messages = st.session_state["message"][-maxHistoryMessages:]

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œå¦‚æœä½¿ç”¨RAGï¼Œåˆ™ç”¨å¢å¼ºåçš„promptæ›¿æ¢æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        messages = [system_message] + user_messages[:-1]
        if use_rag and relevant_chunks:
            # ä½¿ç”¨å¢å¼ºåçš„prompt
            messages.append({"role": "user", "content": prompt})
        else:
            messages.append(user_messages[-1])

        response = client.chat(
            model=selected_model,
            messages=messages,
            stream=use_stream,
            options={"temperature": st.session_state['temperature']}
        )

        if use_stream:
            assistant_message = ""
            assistant_message_placeholder = st.empty()
            for chunk in response:
                if chunk.get("message"):
                    assistant_message += chunk["message"]["content"]
                    assistant_message = preprocess_output(assistant_message)
                    assistant_message_placeholder.markdown(assistant_message)
                    time.sleep(0.05)
            assistant_message = {"role": "assistant", "content": assistant_message}
            st.session_state["message"].append(assistant_message)
        else:
            response['message']['content'] = preprocess_output(response['message']['content'])
            assistant_message = {"role": "assistant", "content": response['message']['content']}
            st.session_state["message"].append(assistant_message)
            st.chat_message("assistant").markdown(response['message']['content'])

    # è°ƒç”¨ Flask åç«¯æ¥å£ä¿å­˜å¯¹è¯
    save_conversation([user_message, assistant_message], user_id, conversation_id)
    return conversation_id


def save_conversation(messages, user_id=1, conversation_id=1):
    """ä¿å­˜å¯¹è¯åˆ°åç«¯"""
    # æ„é€ è¯·æ±‚æ•°æ®
    data = {
        "user_id": user_id,
        "conversation_id": conversation_id,
        "messages": messages
    }

    # è°ƒç”¨ Flask åç«¯æ¥å£ä¿å­˜å¯¹è¯
    try:
        response = requests.post(f"http://127.0.0.1:5000/save_conversation", json=data)
        if response.status_code == 200:
            return conversation_id
        else:
            st.error("ä¿å­˜å¯¹è¯å¤±è´¥ã€‚")
            return None
    except Exception as e:
        st.error(f"ä¿å­˜å¯¹è¯æ—¶å‡ºé”™: {e}")
        return None


def show_rag_settings():
    """æ˜¾ç¤ºRAGè®¾ç½®é€‰é¡¹"""
    st.subheader("ğŸ”§ rag è®¾ç½®")

    # RAGå¼€å…³
    use_rag = st.checkbox(
        "å¯ç”¨RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰",
        value=st.session_state.get('use_rag', False),
        help="å¯ç”¨åå°†åœ¨å›ç­”é—®é¢˜æ—¶æœç´¢ç›¸å…³æ–‡æ¡£å†…å®¹"
    )
    st.session_state['use_rag'] = use_rag

    if use_rag:
        # RAGå‚æ•°è®¾ç½®
        st.subheader("ğŸ“‹ rag å‚æ•°")

        col1, col2 = st.columns(2)

        with col1:
            chunk_size = st.slider(
                "æ–‡æ¡£å—å¤§å°",
                min_value=200,
                max_value=1000,
                value=st.session_state.get('chunk_size', 500),
                help="æ¯ä¸ªæ–‡æ¡£å—çš„å­—ç¬¦æ•°"
            )
            st.session_state['chunk_size'] = chunk_size

        with col2:
            top_k = st.slider(
                "æ£€ç´¢æ–‡æ¡£æ•°é‡",
                min_value=1,
                max_value=10,
                value=st.session_state.get('top_k', 3),
                help="æ¯æ¬¡æŸ¥è¯¢è¿”å›çš„ç›¸å…³æ–‡æ¡£å—æ•°é‡"
            )
            st.session_state['top_k'] = top_k

        # æ˜¾ç¤ºRAGçŠ¶æ€
        if 'rag_system' in st.session_state:
            stats = st.session_state.rag_system.get_document_stats()
            st.info(f"ğŸ“Š RAGçŠ¶æ€: {stats['total_chunks']} ä¸ªæ–‡æ¡£å—ï¼Œ{len(stats['files'])} ä¸ªæ–‡æ¡£")
        else:
            st.warning("âš ï¸ RAGç³»ç»Ÿæœªåˆå§‹åŒ–")

    return use_rag


def display_rag_enhanced_conversation(prompt, file_content, client, selected_model, use_stream, maxHistoryMessages,
                                      conversation_id=1, user_id=1):
    """
    RAGå¢å¼ºçš„å¯¹è¯æ˜¾ç¤ºå‡½æ•°
    """
    use_rag = st.session_state.get('use_rag', False)

    return display_conversation(
        prompt=prompt,
        file_content=file_content,
        client=client,
        selected_model=selected_model,
        use_stream=use_stream,
        maxHistoryMessages=maxHistoryMessages,
        conversation_id=conversation_id,
        user_id=user_id,
        use_rag=use_rag
    )


def show_rag_debug_info():
    """æ˜¾ç¤ºRAGè°ƒè¯•ä¿¡æ¯"""
    if st.session_state.get('show_rag_debug', False) and 'rag_system' in st.session_state:
        st.subheader("ğŸ” rag è°ƒè¯•ä¿¡æ¯")

        rag_system = st.session_state.rag_system
        stats = rag_system.get_document_stats()

        # æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡
        st.json({
            "æ–‡æ¡£ç»Ÿè®¡": stats,
            "å…³é”®è¯ç¤ºä¾‹": list(rag_system.index.keyword_index.keys())[:10] if rag_system.index.keyword_index else []
        })

        # æµ‹è¯•æŸ¥è¯¢
        test_query = st.text_input("æµ‹è¯•æŸ¥è¯¢", placeholder="è¾“å…¥æµ‹è¯•æŸ¥è¯¢...")
        if test_query:
            results = rag_system.search_documents(test_query, top_k=5)
            st.write(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£å—:")
            for i, result in enumerate(results):
                st.write(f"**ç»“æœ {i + 1}** (ç›¸å…³æ€§: {result['relevance_score']:.2f})")
                st.write(f"æ¥æº: {result['filename']}")
                st.write(f"å†…å®¹: {result['content'][:200]}...")
                st.write("---")
