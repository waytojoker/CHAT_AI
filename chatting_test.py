import time
import streamlit as st
import re
from modules import file_processing
from modules.conversation_display import display_conversation
from modules.history_module import show_conversation_history
import requests
from model_service import create_model_service  # å¯¼å…¥æ¨¡å‹æœåŠ¡å·¥å‚

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="æ™ºè”æœªæ¥-æ™ºèƒ½åŠ©æ‰‹", page_icon="ğŸ¤–")
maxHistoryMessages = 10

# å¯¼å…¥æ¨¡æ¿é…ç½®
from modules.xhs_prompt import XHS_ROLE_CONFIG, XHS_SCENE_CONFIG, XHS_TASK_CONFIG
from modules.gzh_prompt import GZH_ROLE_CONFIG, GZH_SCENE_CONFIG, GZH_TASK_CONFIG


# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
def init_session_state():
    session_vars = {
        "message": [],
        "model_service": None,
        'role_config': "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œèƒ½å¤Ÿå›ç­”å„ç§é—®é¢˜å¹¶æä¾›å¸®åŠ©ã€‚",
        'scene_config': "åœ¨ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„å¯¹è¯ç¯å¢ƒä¸­",
        'task_config': "è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”",
        'temperature': 0.7,
        'conversation_id': None,
        "show_history": False,
        'file_content': "",
        'selected_service': "Ollama"  # æ–°å¢æœåŠ¡ç±»å‹çŠ¶æ€
    }
    for key, value in session_vars.items():
        if key not in st.session_state:
            st.session_state[key] = value


init_session_state()


def get_system_prompt():
    return f"""è§’è‰²è®¾å®šï¼š{st.session_state['role_config']}
åœºæ™¯è®¾å®šï¼š{st.session_state['scene_config']}
ä»»åŠ¡è¦æ±‚ï¼š{st.session_state['task_config']}"""


# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®è®¾ç½®")

    # æ“ä½œæŒ‰é’®
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("ğŸ“– å†å²è®°å½•"):
            st.session_state["show_history"] = not st.session_state["show_history"]
    with col2:
        if st.button("ğŸ“ æ–°å»ºå¯¹è¯"):
            response = requests.post("http://127.0.0.1:5000/new_conversation", json={"user_id": 1})
            if response.status_code == 200:
                st.session_state.update({
                    "conversation_id": response.json()["conversation_id"],
                    "message": [],
                    "show_history": False
                })
                st.rerun()
            else:
                st.error("æ–°å»ºå¯¹è¯å¤±è´¥")

    # æ–‡ä»¶ä¸Šä¼ 
    st.subheader("â˜ï¸ ä¸Šä¼ æ–‡ä»¶")
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ æ–‡ä»¶",
        type=["docx", "pdf", "png", "jpg", "txt", "xlsx", "pptx"],
        accept_multiple_files=True
    )
    if uploaded_files:
        st.session_state['file_content'] = file_processing.get_file_content(uploaded_files)
        st.success(f"å·²åŠ è½½ {len(uploaded_files)} ä¸ªæ–‡ä»¶")

    # æ¨¡å‹é…ç½®
    st.subheader("ğŸ¤– æ¨¡å‹é…ç½®")

    # æœåŠ¡ç±»å‹é€‰æ‹©
    st.session_state['selected_service'] = st.selectbox(
        "é€‰æ‹©æœåŠ¡ç±»å‹",
        ["Ollama", "Qianfan"],
        index=0 if st.session_state['selected_service'] == "Ollama" else 1
    )

    # Ollamaé…ç½®
    if st.session_state['selected_service'] == "Ollama":
        ollama_host = st.text_input("OllamaæœåŠ¡åœ°å€", value="http://127.0.0.1:11434")
        ollama_models = ["deepseek-r1:7b", "deepseek-r1:1.5b"]  # åŒ…å«åŸæœ‰ä¸¤ä¸ªdeepseekæ¨¡å‹
        selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", ollama_models)

        if st.button("è¿æ¥OllamaæœåŠ¡"):
            try:
                st.session_state["model_service"] = create_model_service(
                    service_type="ollama",
                    host=ollama_host,
                    model=selected_model
                )
                st.success(f"{selected_model} è¿æ¥æˆåŠŸ")
            except Exception as e:
                st.error(f"è¿æ¥å¤±è´¥: {str(e)}")

    # åƒå¸†é…ç½®
    elif st.session_state['selected_service'] == "Qianfan":
        qianfan_auth = st.text_input("åƒå¸†æˆæƒä»¤ç‰Œ", type="password")
        qianfan_models = ["ernie-4.5-turbo-vl-32k", "ernie-3.5"]
        selected_model = st.selectbox("åƒå¸†æ¨¡å‹", qianfan_models)

        if st.button("è¿æ¥åƒå¸†æœåŠ¡"):
            try:
                st.session_state["model_service"] = create_model_service(
                    service_type="qianfan",
                    authorization=qianfan_auth,
                    model=selected_model
                )
                st.success(f"{selected_model} è¿æ¥æˆåŠŸ")
            except Exception as e:
                st.error(f"è¿æ¥å¤±è´¥: {str(e)}")

    # æµå¼å“åº”å¼€å…³
    use_stream = st.checkbox("ä½¿ç”¨æµå¼å“åº”", value=True)

    # Prompté…ç½®
    st.subheader("ğŸ“ Prompté…ç½®")
    st.session_state['role_config'] = st.text_area("è§’è‰²é…ç½®", value=st.session_state['role_config'], height=100)
    st.session_state['scene_config'] = st.text_area("åœºæ™¯é…ç½®", value=st.session_state['scene_config'], height=80)
    st.session_state['task_config'] = st.text_area("ä»»åŠ¡é…ç½®", value=st.session_state['task_config'], height=80)

    # æ¨¡æ¿é€‰æ‹©
    template = st.selectbox("ğŸ“‹ é€‰æ‹©ä»»åŠ¡æ¨¡æ¿", ["è‡ªå®šä¹‰", "å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆ", "å…¬ä¼—å·é”™å­—è¯†åˆ«"])
    if st.button("åº”ç”¨æ¨¡æ¿"):
        if template == "å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆ":
            st.session_state.update({
                'role_config': XHS_ROLE_CONFIG,
                'scene_config': XHS_SCENE_CONFIG,
                'task_config': XHS_TASK_CONFIG
            })
        elif template == "å…¬ä¼—å·é”™å­—è¯†åˆ«":
            st.session_state.update({
                'role_config': GZH_ROLE_CONFIG,
                'scene_config': GZH_SCENE_CONFIG,
                'task_config': GZH_TASK_CONFIG
            })
        st.rerun()

    # å‚æ•°é…ç½®
    st.subheader("ğŸ›ï¸ å‚æ•°é…ç½®")
    st.session_state['temperature'] = st.slider("Temperature", 0.0, 2.0, st.session_state['temperature'], 0.1)

    # æ“ä½œæŒ‰é’®
    if st.button("ğŸ”„ é‡ç½®é…ç½®"):
        st.session_state.update({
            'role_config': "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œèƒ½å¤Ÿå›ç­”å„ç§é—®é¢˜å¹¶æä¾›å¸®åŠ©ã€‚",
            'scene_config': "åœ¨ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„å¯¹è¯ç¯å¢ƒä¸­",
            'task_config': "è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”",
            'temperature': 0.7
        })
        st.rerun()

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²"):
        st.session_state["message"] = []
        st.rerun()

# ä¸»ç•Œé¢
st.title("æ™ºè”æœªæ¥")
st.divider()

# æ˜¾ç¤ºå½“å‰æ¨¡å‹æœåŠ¡çŠ¶æ€
current_service = st.session_state.get("model_service")
if current_service:
    service_type = "Ollama" if hasattr(current_service, 'client') else "Qianfan"
    st.caption(f"ğŸŒ¡ï¸ Temperature: {st.session_state['temperature']} | ğŸ”§ å½“å‰æœåŠ¡: {service_type}")

# æ˜¾ç¤ºå†å²è®°å½•
if st.session_state["show_history"]:
    conversation_id = show_conversation_history(user_id=1, show_history=True)
    st.session_state["conversation_id"] = conversation_id
    if conversation_id:
        for message in st.session_state["message"]:
            content = message["content"]
            if message["role"] == "user" and "ç”¨æˆ·æé—®ï¼š" in content:
                content = content.split("ç”¨æˆ·æé—®ï¼š")[-1]
            st.chat_message(message["role"]).markdown(content)
elif st.session_state["conversation_id"]:
    conversation_id = st.session_state["conversation_id"]

# èŠå¤©è¾“å…¥
prompt = st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
if prompt:
    if not st.session_state["model_service"]:
        st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ è¿æ¥æ¨¡å‹æœåŠ¡ï¼")  # æ·»åŠ æ˜ç¡®çš„é”™è¯¯æç¤º
    else:
        if st.session_state.get("conversation_id"):
            display_conversation(
                prompt=prompt,
                file_content=st.session_state.get('file_content', ''),
                model_service=st.session_state["model_service"],
                use_stream=use_stream,
                maxHistoryMessages=maxHistoryMessages,
                conversation_id=st.session_state["conversation_id"],
                user_id=1,
            )
        else:
            st.session_state["conversation_id"] = display_conversation(
                prompt=prompt,
                file_content=st.session_state.get('file_content', ''),
                model_service=st.session_state["model_service"],
                use_stream=use_stream,
                maxHistoryMessages=maxHistoryMessages,
            )
